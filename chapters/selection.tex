\section{Выбор исходных образцов и стратегий мутации}

При применении генеративного подхода решающую роль играет выбор образцов, которые станут источником для генерации, а также самих стратегий мутации. Например, применение битфлипов при фаззинге интерпретатора не даст пройти стадию корректно работающего лексического анализа, но в то время эта же стратегия может помочь обнаружить ошибки в парсере изображений. Для выбора исходных образцов необходимо выделение уникальных путей в программе и предпочтение мутации образцов, дающих наибольшее покрытие. При выборе стратегий мутации оказываются полезны некоторые методы решения задач о принятии решений в условии неопределённости, в частности для задачи о многоруких бандитах. Далее будут рассмотрены эти вопросы.

\subsection{Выбор образцов на основе покрытия}

Частой проблемой при фаззинге является медленное исследование отдалённых участков программы, связанное с тем, что фаззер не обладает информацией о том, каким путём может быть достижим тот или иной её участок и в следствие этого вынужден выбирать, какой образец мутировать случайным образом. Часто применяемой эвристикой для борьбы с этим является предпочтение тех образцов, которые имеют наибольшее покрытие программы в надежде, что их мутирование позволит продвинуться дальше.

Фаззеры формулируют пути в программе по-разному. Afl в частности вместо просто понимая покрытия как количества посещённых функций, базовых блоков или других структурных элементов рассматривает программу как конечный автомат и отслеживает переходы между его состояниями. При этом ещё и выполняется подсчёт каждого типа переходов и происходит разделение числа переходов на эмпирически подобранные классы эквивалентности, за счёт чего, с одной стороны, мы получаем, например, возможность отыскивать нередко приводящие к неожиданному поведению двойное исполнение блоков кода, и с другой стороны не проводим различий между примерами, при обработке которых используются многократно работающие циклы.

Аналогично afl предлагается использовать выделение классов эквивалентности, выделяя однократно, двукратно и многократно посещённые участки программы. Путь в программе представляется как словарь, ключами в котором являются адреса посещённых участков программы, а значениями -- классы эквивалентности. Данный подход, помимо прочего, позволяет убирать из программы точки останова после попадания адреса в класс многократно выполняющихся участков после выполнения трёх и более раз, за счёт чего влияние на скорость выполнения программы будет ограниченно числом точек останова и не будет постоянно возрастать, но в то же время мы по-прежнему имеем возможность узнать, был ли достигнут новый её участок.

Выбор кандидата на мутацию происходит с вероятностью, задаваемой простой формулой:
\begin{equation*}
	p_i = \frac{n_i}{\sum_{k=1}^{m} n_k},
	\vspace{5pt}
\end{equation*}

\noindent где $n_i$ это число уникальных точек в программе, посещённых при запуске $i$-го примера, а $p_i$ - вероятность выбора $i$-го примера.

\subsection{Задача о многоруких бандитах}

Задача о многоруких бандитах является одной из классических задач принятия решений в условиях неопределённости, а также обучении с подкреплением и находит применение в разных областях, например в медицине как потенциально более эффективный способ поиска лекарств или в рекламе для выбора наиболее подходящих рекламных баннеров \cite{bandits}. В своём классическом виде задача формулируется следующим образом: имеется $K$ случайных распределений с математическими ожиданиями $\mu_i$ и стандартными отклонениями $\sigma_i$, соответствующих игральным автоматам (отсюда название). На каждом ходу игрок выбирает один из автоматов и тянет за ручку, тем самым получая некоторый выигрыш, определяемый соответствующим распределением. Целью игрока является максимизация выигрыша. При этом параметры распределений изначально неизвестны, игроку доступна лишь оценка этих параметров на основании своих предыдущих выборов и наблюдавшихся результатов, перед игроком стоит выбор между использованием какого-то автомата, который он считает наилучшим, и исследованием остальных распределений в попытке собрать больше информации и потенциально найти более хороший вариант.

Для измерения качества алгоритма как правило применяется метрика, отражающая общее количество недополученного выигрыша за $T$ шагов, формулируемая следующим образом:
\vspace{5pt}
\begin{equation*}
	R_T = T \mu^* - \sum_{t=1}^{T} \mu_j (t), \ \mathrm{где} \ \mu^* = \max_{i=1,...,K} \mu_i
\end{equation*} 
\vspace{7pt}
то есть $\mu^*$ это математическое ожидание наилучшего распределения.

\vspace{-10pt}
Если проводить параллели с генерацией данных для фаззинга, то вместо игровых автоматов мы выбираем среди набора стратегий мутации, а в качестве выигрыша рассматривается то, как много участков программы удалось покрыть сгенерированным при применении мутации образцом.

\subsection{Алгоритмы для задачи о многоруких бандитах}